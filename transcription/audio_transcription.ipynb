{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [00:34<00:00, 44.3MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salgu/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"audio/2016.02.21_01.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The text: \n",
      "  요렇게 홍서핀과 청소 재왕 홍서핀과 청소의 재왕 불거리와 목감아 돌리게 좋떡기를 가지고 있죠? 홍서핀과? 자 강략한 물이 치기입니다 비겨쳐보는 재왕? 홍서핀과 감아 돌립니다 홍서핀과 홍서핀과 홍서핀과 홍서핀과 홍서핀과 청소 재왕 재왕의 반격 감아 돌리는 재왕 여덟살에 동만내기지요 홍서핀과 자 목감아 돌리게 기술을 시도해 봤던 청소 재왕? 홍서핀과 자 일단 그리를 때받는데요 홍서재왕 청소 재왕 단발성 비겨치기 자 홍서핀과 물로 씁니다 자 홍서핀과 그렇게 13인 물로 씁니다 자 청소 재왕 홍서핀과 왼 볼 비겨치기 시대 보는 재왕? 홍서핀과 홍서핀과 홍서핀과 홍서핀과 자 견기장 중앙에에서 엄청난 물에 치기를 주고받고 있습니다 일라운드 견기회시간 얼마나 남지 않았습니다? 자 청소 재왕? 견기회 주도군을 잡았나요? 홍서핀과? 견기회 주도군을 잡았나요? 가만 돌리는 재왕? 자 엄청납니다 다시 물이 맞때곤 밀어버린 두 마리 삼소들? 홍서핀과? 청소 재왕? 자 이라운드로 접어들었습니다 자 여기서 청소핀과? 청소 재왕? 목구마 돌리기 기술을 시대 봄 담아만한 홍서핀과 잘 받아났습니다 자 두 마리 삼소들 이마에 붉은 비챌보이기 뛰고 있습니다 엄청난 총격을 받았죠 자 여기서 청소 재왕? 담발번에 공작 날라봅니다 자 여기서 빈거 물러섭니다 한발불러 섰는데요? 따라 들어가는 재왕? 자 여기서 Mike은 두번 하기로 바로 출발 motives\n"
     ]
    }
   ],
   "source": [
    "print(f' The text: \\n {result[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The text: \n",
      "  자 빙고 치고 갑니다 홍소 빙고 청소제왕 자 홍소 빙고 청소제왕 뿔거리와 목감아 돌리기의 주특결을 가지고 있죠 홍소 빙고 자 강력한 머리치기입니다 자 비껴 쳐보는 제왕 홍소 빙고 감아돌립니다 자 엄청난 단발선 공격인데요 홍소 빙고 자 밀고 들어가는 빙고 청소제왕 제왕의 반격 감아돌리는 제왕 8살의 동갑내기죠 자 목감아 돌리기 기술을 시도해 봤던 청소제왕 자 일단 거리를 떼봤는데요 홍소 제왕 빙고 청소제왕 단발선 빙고치기 자 홍소 빙고 물렀습니까 자 홍소 빙고 그렇게 10살이 물렀을 빙고가 아닌데요 자 청소제왕 왼불 빗게 치기 시대 보는 제왕 홍소 빙고 자 이 경기장 중앙에서 엄청난 머리치기를 주고받고 있습니다 1라운드 경기 시간 얼마 남지 않았습니다 자 청소제왕 경기의 주도꾼을 잡았나요 홍소 빙고 경기의 주도꾼을 잡았나요 감아돌리는 제왕 자 엄청납니다 다시 머리 맞대고 밀어보는 두 마리 삼소들 홍소의 빙고 청소제왕 자 2라운드로 접어들었습니다 자 여기서 청소 빙고 청소제왕 목꼬마 돌리기의 기술을 시대 봅니다만 홍소 빙고 잘 받아 냈습니다 자 두 마리 삼소들 이마에 붉은 빛을 보이고 있습니다 엄청난 충격을 받았죠 자 여기서 청소제왕 단발선 공격 날라봅니다 자 여기서 빙고 물러섭니다 한 마리 물러섰는데요 따라 들어가는 제왕 자 여기서 제1경기\n"
     ]
    }
   ],
   "source": [
    "print(f' The text: \\n {result[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers torch\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper = pipeline(\n",
    "    \"automatic-speech-recognition\", \n",
    "    # \"openai/whisper-large-v3\", \n",
    "    # \"openai/whisper-large-v3-turbo\",\n",
    "    \"ghost613/whisper-large-v3-turbo-korean\",\n",
    "    torch_dtype=torch.float16, \n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salgu/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    }
   ],
   "source": [
    "transcription = whisper(\n",
    "    \"audio/2016.02.21_01.mp3\",\n",
    "    return_timestamps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 자 빙고 치러 갑니다. 홍서 빙고 청서 제왕 자 홍서 빙고 청소의 제왕 뿔거리와 목감아 돌리기의 주택기를 가지고 있죠 홍소빙고 자 강력한 머리치기입니다 비껴쳐보는 제왕 홍석빙고 가마 돌립니다 자 엄청난 단발성 공격인데요 홍석빙고 밀고 들어가는 빙고 청소 제왕 제왕의 반격 감아 돌리는 제왕 8살의 동갑내기지요 자 목감아 돌리기 기술을 시도해 봤던 청소재환 자 일단 그리를 떼봤는데요 홍소 제왕 빙고 청소 제왕 단발성 비껴치기 홍소 빙고 물러섭니까 자 홍섭 빙고 그렇게 쉽사리 물러설 빙고가 아닌데요 자 청서 제왕 왼불 비껴치기 시대보는 제왕 홍서빙고 자 이 경기장 중앙에서 엄청난 무리치기를 주고받고 있습니다 1라운드 경기시간 얼마 남지 않았습니다 자 청소 제왕 경기의 주도꾼을 잡았나요 홍소 빙고 경기의 주도꾼을 잡았나요 가만 돌리는 제왕 자 엄청납니다 다시 머리만 떼고 밀어버는 두 마리 삼소들 홍수의 빙고 청소의 제왕 자 2라운드로 접어들었습니다 자 여기서 청소 빙고 청소 제왕 목고마 돌리기의 기술을 시도해 봅니다만 홍수 빙고 잘 받아 냈습니다. 자 두 마리 삼소들 이마에 붉은 빛을 보이고 있습니다. 난 충격을 받았지요. 자 여기서 청소 제왕 단발성 공격 날라 봅니다. 자 여기서 빙고 물러섭니다. 한 번 물러섰는데요. 따라 들어가는 제왕 자 여기서 제1경기\n"
     ]
    }
   ],
   "source": [
    "print(transcription[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whisper-large-v3-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(18538) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/Users/salgu/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transcription = whisper(\n",
    "    \"audio/2016.02.21_01.mp3\",\n",
    "    return_timestamps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 자 빙고 치료입니다 홍서 빙고 청서 제왕 자 홍서 빙고 청소의 제왕 뿔거리와 목감아 돌리게 주택기를 가지고 있죠 홍소 빙고 자 강력한 무리치기입니다 비껴쳐보는 제왕 홍소 빙고 가마 돌립니다 자 엄청난 단발선 공격인데요 홍소 빙고 밀고 들어가는 빙고 청소제왕 제왕의 반격 감아 돌리는 제왕 8살의 동갑내기죠 목감아 돌리기 기술을 시도해봤던 청소재환 자 일단 그리를 떼 봤는데요 홍소, 빙고 청소, 제왕 단발성, 비껴치기 홍소, 빙고 물러섭니까 홍소, 빙고 그렇게 쉽사리 물러설 빈고가 아닌데요 자 청소 제왕 왼불 비껴치기 시대 보는 제왕 홍서 빙고 자 이 경기장 중앙에서 엄청난 무리치기를 주고받고 있습니다 1라운드 경기시간 얼마 남지 않았습니다 청소제왕 경기의 주도권을 잡았나요? 홍소 빙고 경기의 주도권을 잡았나요? 가만 돌리는 제왕 엄청납니다 다시 머리 맞대고 밀어보는 두 마리 삼초들. 홍소의 빙고. 청소의 제왕. 2라운드로 접어들었습니다. 자 여기서 청소 빙고 청소제왕 목고마 돌리기의 기술을 시대봅니다만 홍소 빙고 잘 받아 냈습니다 두 마리 사움소들 이마에 붉은 빛을 보이게 뛰고 있습니다 엄청난 충격을 받았죠 자 여기서 청소 제왕 단발선 공격 날라봅니다. 자 여기서 빈곱 물러섭니다. 한발 물러섰는데요. 따라 들어가는 제왕. 자 여기서 제1경기\n"
     ]
    }
   ],
   "source": [
    "print(transcription[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whisper large v3 korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "whisper = pipeline(\n",
    "    \"automatic-speech-recognition\", \n",
    "    \"ghost613/whisper-large-v3-turbo-korean\",\n",
    "    torch_dtype=torch.float16, \n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(48557) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/Users/salgu/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to return timestamps, but the generation config is not properly set. Make sure to initialize the generation config with the correct attributes that are needed such as `no_timestamps_token_id`. For more details on how to generate the approtiate config, refer to https://github.com/huggingface/transformers/issues/21878#issuecomment-1451902363",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m transcription = \u001b[43mwhisper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio/2016.02.21_01.mp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# return_timestamps=True\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlanguage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkorean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranscribe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:283\u001b[39m, in \u001b[36mAutomaticSpeechRecognitionPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    224\u001b[39m     inputs: Union[np.ndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    225\u001b[39m     **kwargs,\n\u001b[32m    226\u001b[39m ):\n\u001b[32m    227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m    documentation for more information.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    281\u001b[39m \u001b[33;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1360\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[32m   1359\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1275\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1274\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:521\u001b[39m, in \u001b[36mAutomaticSpeechRecognitionPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, return_timestamps, **generate_kwargs)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    519\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m tokens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;66;03m# whisper longform generation stores timestamps in \"segments\"\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps == \u001b[33m\"\u001b[39m\u001b[33mword\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.type == \u001b[33m\"\u001b[39m\u001b[33mseq2seq_whisper\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:597\u001b[39m, in \u001b[36mWhisperGenerationMixin.generate\u001b[39m\u001b[34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, time_precision_features, return_token_timestamps, return_segments, return_dict_in_generate, force_unique_generate_call, **kwargs)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# 3. Make sure generation config is correctly set\u001b[39;00m\n\u001b[32m    590\u001b[39m \u001b[38;5;66;03m# Make sure the generation config is correctly set depending on whether timestamps are to be returned or not\u001b[39;00m\n\u001b[32m    591\u001b[39m return_dict_in_generate = \u001b[38;5;28mself\u001b[39m._set_return_outputs(\n\u001b[32m    592\u001b[39m     return_dict_in_generate=return_dict_in_generate,\n\u001b[32m    593\u001b[39m     return_token_timestamps=return_token_timestamps,\n\u001b[32m    594\u001b[39m     logprob_threshold=logprob_threshold,\n\u001b[32m    595\u001b[39m     generation_config=generation_config,\n\u001b[32m    596\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m timestamp_begin = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_return_timestamps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_timestamps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_timestamps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28mself\u001b[39m._set_language_and_task(\n\u001b[32m    601\u001b[39m     language=language, task=task, is_multilingual=is_multilingual, generation_config=generation_config\n\u001b[32m    602\u001b[39m )\n\u001b[32m    603\u001b[39m \u001b[38;5;28mself\u001b[39m._set_num_frames(\n\u001b[32m    604\u001b[39m     return_token_timestamps=return_token_timestamps, generation_config=generation_config, kwargs=kwargs\n\u001b[32m    605\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/1_project/cow/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1316\u001b[39m, in \u001b[36mWhisperGenerationMixin._set_return_timestamps\u001b[39m\u001b[34m(self, return_timestamps, is_shortform, generation_config)\u001b[39m\n\u001b[32m   1313\u001b[39m     return_timestamps = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[33m\"\u001b[39m\u001b[33mno_timestamps_token_id\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1316\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1317\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to return timestamps, but the generation config is not properly set. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1318\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMake sure to initialize the generation config with the correct attributes that are needed such as `no_timestamps_token_id`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFor more details on how to generate the approtiate config, refer to https://github.com/huggingface/transformers/issues/21878#issuecomment-1451902363\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1320\u001b[39m     )\n\u001b[32m   1322\u001b[39m generation_config.return_timestamps = return_timestamps\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[33m\"\u001b[39m\u001b[33mno_timestamps_token_id\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: You are trying to return timestamps, but the generation config is not properly set. Make sure to initialize the generation config with the correct attributes that are needed such as `no_timestamps_token_id`. For more details on how to generate the approtiate config, refer to https://github.com/huggingface/transformers/issues/21878#issuecomment-1451902363"
     ]
    }
   ],
   "source": [
    "transcription = whisper(\n",
    "    \"audio/2016.02.21_01.mp3\",\n",
    "    # return_timestamps=True\n",
    "    generate_kwargs={\"language\":\"korean\",\"task\":\"transcribe\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 자 빙고 치료입니다 홍서 빙고 청서 제왕 자 홍서 빙고 청소의 제왕 뿔거리와 목감아 돌리게 주택기를 가지고 있죠 홍소 빙고 자 강력한 무리치기입니다 비껴쳐보는 제왕 홍소 빙고 가마 돌립니다 자 엄청난 단발선 공격인데요 홍소 빙고 밀고 들어가는 빙고 청소제왕 제왕의 반격 감아 돌리는 제왕 8살의 동갑내기죠 목감아 돌리기 기술을 시도해봤던 청소재환 자 일단 그리를 떼 봤는데요 홍소, 빙고 청소, 제왕 단발성, 비껴치기 홍소, 빙고 물러섭니까 홍소, 빙고 그렇게 쉽사리 물러설 빈고가 아닌데요 자 청소 제왕 왼불 비껴치기 시대 보는 제왕 홍서 빙고 자 이 경기장 중앙에서 엄청난 무리치기를 주고받고 있습니다 1라운드 경기시간 얼마 남지 않았습니다 청소제왕 경기의 주도권을 잡았나요? 홍소 빙고 경기의 주도권을 잡았나요? 가만 돌리는 제왕 엄청납니다 다시 머리 맞대고 밀어보는 두 마리 삼초들. 홍소의 빙고. 청소의 제왕. 2라운드로 접어들었습니다. 자 여기서 청소 빙고 청소제왕 목고마 돌리기의 기술을 시대봅니다만 홍소 빙고 잘 받아 냈습니다 두 마리 사움소들 이마에 붉은 빛을 보이게 뛰고 있습니다 엄청난 충격을 받았죠 자 여기서 청소 제왕 단발선 공격 날라봅니다. 자 여기서 빈곱 물러섭니다. 한발 물러섰는데요. 따라 들어가는 제왕. 자 여기서 제1경기\n"
     ]
    }
   ],
   "source": [
    "print(transcription[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
